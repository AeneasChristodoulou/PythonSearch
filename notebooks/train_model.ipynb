{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from search_run.ranking.ranking import Ranking\n",
    "from pyspark.sql.session import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "features = ['position', 'key_lenght' ]\n",
    "label = 'input_lenght'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|position|key_lenght|\n",
      "+--------+----------+\n",
      "|       1|        41|\n",
      "|       2|        16|\n",
      "|       3|        36|\n",
      "|       4|        33|\n",
      "|       5|        53|\n",
      "|       6|        21|\n",
      "|       7|         7|\n",
      "|       8|        28|\n",
      "|       9|        20|\n",
      "|      10|        26|\n",
      "|      11|        30|\n",
      "|      12|        16|\n",
      "|      13|        23|\n",
      "|      14|        38|\n",
      "|      15|        15|\n",
      "|      16|        32|\n",
      "|      17|        24|\n",
      "|      18|        22|\n",
      "|      19|        14|\n",
      "|      20|        34|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entries_df = Ranking().load_entries_df(spark)\n",
    "#entries_df = entries_df.drop(\"content\")\n",
    "entries_df = entries_df.withColumn('key_lenght', F.length('key'))\n",
    "entries_df.select('position', 'key_lenght').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+\n",
      "|input_lenght|     generated_date|\n",
      "+------------+-------------------+\n",
      "|          15|2021-08-28 05:04:19|\n",
      "|          16|2021-08-28 05:01:59|\n",
      "|          14|2021-08-27 21:32:54|\n",
      "|           4|2021-08-27 21:22:42|\n",
      "|           7|2021-08-27 21:18:39|\n",
      "|           9|2021-08-27 21:00:34|\n",
      "|          14|2021-08-27 21:00:17|\n",
      "|           9|2021-08-27 20:55:48|\n",
      "|           8|2021-08-27 20:53:04|\n",
      "|           5|2021-08-27 20:46:58|\n",
      "|           5|2021-08-27 18:07:43|\n",
      "|           7|2021-08-27 18:01:32|\n",
      "|           9|2021-08-27 17:56:18|\n",
      "|          18|2021-08-27 17:56:00|\n",
      "|          18|2021-08-27 17:55:55|\n",
      "|           9|2021-08-27 17:55:44|\n",
      "|           3|2021-08-27 17:48:18|\n",
      "|          10|2021-08-27 17:47:43|\n",
      "|          10|2021-08-27 17:47:39|\n",
      "|          19|2021-08-27 17:08:03|\n",
      "+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Ranking().load_commands_performed_df()\n",
    "schema = '`key` STRING,  `generated_date` STRING, `uuid` STRING, `given_input` STRING'\n",
    "original_df = spark.createDataFrame(dataset, schema=schema)\n",
    "performed_df = original_df.withColumn(\"input_lenght\", F.length(\"given_input\"))\n",
    "performed_df = performed_df.filter('given_input != \"NaN\"')\n",
    "performed_df = performed_df.drop('uuid')\n",
    "\n",
    "performed_df.select('input_lenght', 'generated_date').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+\n",
      "|position|key_lenght|input_lenght|\n",
      "+--------+----------+------------+\n",
      "|    3873|        19|         134|\n",
      "|    3873|        19|         134|\n",
      "|     630|        27|          10|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "|     630|        27|          27|\n",
      "+--------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = performed_df.join(entries_df, on='key', how='left')\n",
    "df = df.filter('position is not null')\n",
    "\n",
    "df.select(*features, label).show()\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3873,   19],\n       [3873,   19],\n       [ 630,   27],\n       ...,\n       [ 988,   15],\n       [ 988,   15],\n       [1943,   24]])"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(df.select(*features).collect())\n",
    "Y = np.array(df.select(label).collect())\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-122-553f8fb8cc23>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = regr.fit(X, Y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "log_model() missing 1 required positional argument: 'artifact_path'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-122-553f8fb8cc23>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mregr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRandomForestRegressor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_depth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mregr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mmlflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: log_model() missing 1 required positional argument: 'artifact_path'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "    model = regr.fit(X, Y)\n",
    "    mlflow.sklearn.log_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(position, key_lenght):\n",
    "    \"\"\" function to predict used at the udf \"\"\"\n",
    "    return float(model.predict(np.array([[position, key_lenght]]))[0])\n",
    "\n",
    "model_udf = udf(evaluate_model, FloatType())\n",
    "\n",
    "result_df = entries_df.withColumn(\"predicted_key_lenght\", model_udf(F.col('position'), F.col('key_lenght')))\n",
    "#result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyse results - easiest to find"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+\n",
      "|position|key_lenght|predicted_key_lenght|\n",
      "+--------+----------+--------------------+\n",
      "|    2460|        15|           23.089348|\n",
      "|    2455|        24|           23.089348|\n",
      "|    2446|        22|           23.089348|\n",
      "|    2451|        19|           23.089348|\n",
      "|    2434|        16|           23.089348|\n",
      "|    2441|        22|           23.089348|\n",
      "|    2459|        26|           23.089348|\n",
      "|    2448|        13|           23.089348|\n",
      "|    2429|        10|           23.089348|\n",
      "|    2468|        12|           23.089348|\n",
      "|    2454|        18|           23.089348|\n",
      "|    2438|        27|           23.089348|\n",
      "|    2457|        19|           23.089348|\n",
      "|    2458|        20|           23.089348|\n",
      "|    2444|        18|           23.089348|\n",
      "|    2447|        24|           23.089348|\n",
      "|    2469|        17|           23.089348|\n",
      "|    2427|        13|           23.089348|\n",
      "|    2449|        23|           23.089348|\n",
      "|    2453|        13|           23.089348|\n",
      "+--------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_df.select(*features, 'predicted_key_lenght').orderBy(F.col('predicted_key_lenght').asc()).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Analyse results - hardest to find"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+\n",
      "|position|key_lenght|predicted_key_lenght|\n",
      "+--------+----------+--------------------+\n",
      "|     119|        43|           150.99907|\n",
      "|     105|        47|           150.99907|\n",
      "|     117|        44|           150.99907|\n",
      "|      26|        52|           150.99907|\n",
      "|     134|        41|           150.99907|\n",
      "|      93|        55|           150.99907|\n",
      "|     102|        43|           150.99907|\n",
      "|      24|        41|           150.99907|\n",
      "|      53|        48|           150.99907|\n",
      "|       5|        53|           150.99907|\n",
      "|       1|        41|           150.99907|\n",
      "|      50|        50|           150.99907|\n",
      "|      59|        54|           150.99907|\n",
      "|      99|        56|           150.99907|\n",
      "|      94|        45|           150.99907|\n",
      "|      31|        45|           150.99907|\n",
      "|      71|        41|           150.99907|\n",
      "|      47|        48|           150.99907|\n",
      "|      44|        43|           150.99907|\n",
      "|      77|        44|           150.99907|\n",
      "+--------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_df.select(*features,'predicted_key_lenght',).orderBy(F.col('predicted_key_lenght').desc\n",
    "                                                                                  ()).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save output\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 key|predicted_key_lenght|\n",
      "+--------------------+--------------------+\n",
      "|engineering categ...|           150.99907|\n",
      "|growth budget per...|           150.99907|\n",
      "|troubleshooting s...|           150.99907|\n",
      "|data platform dat...|           150.99907|\n",
      "|how i want to beh...|           150.99907|\n",
      "|accompliments per...|           150.99907|\n",
      "|remove us from fa...|           150.99907|\n",
      "|buy train ticket ...|           150.99907|\n",
      "|databricks repres...|           150.99907|\n",
      "|become the ml pla...|           150.99907|\n",
      "|filter available ...|           150.99907|\n",
      "|champions league ...|           150.99907|\n",
      "|360 review cycle ...|           150.99907|\n",
      "|context aware ran...|           150.99907|\n",
      "|vertex ai feature...|           150.99907|\n",
      "|inspect python ob...|           150.99907|\n",
      "|data integration ...|           150.99907|\n",
      "|growth framework ...|           150.99907|\n",
      "|deliverables q4 t...|           150.99907|\n",
      "|dont know how and...|           150.99907|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|                 key|predicted_key_lenght|\n",
      "+--------------------+--------------------+\n",
      "|engineering categ...|           150.99907|\n",
      "|context aware ran...|           150.99907|\n",
      "|troubleshooting s...|           150.99907|\n",
      "|360 review cycle ...|           150.99907|\n",
      "|accompliments per...|           150.99907|\n",
      "|vertex ai feature...|           150.99907|\n",
      "|remove us from fa...|           150.99907|\n",
      "|how i want to beh...|           150.99907|\n",
      "|champions league ...|           150.99907|\n",
      "|growth budget per...|           150.99907|\n",
      "|growth framework ...|           150.99907|\n",
      "|dont know how and...|           150.99907|\n",
      "|filter available ...|           150.99907|\n",
      "|data platform dat...|           150.99907|\n",
      "|databricks repres...|           150.99907|\n",
      "|become the ml pla...|           150.99907|\n",
      "|data integration ...|           150.99907|\n",
      "|deliverables q4 t...|           150.99907|\n",
      "|inspect python ob...|           150.99907|\n",
      "|buy train ticket ...|           150.99907|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = result_df.select('key', 'predicted_key_lenght').orderBy(F.col('predicted_key_lenght').desc())\n",
    "output.show()\n",
    "import shutil\n",
    "shutil.rmtree('/data/search_run/predict_input_lenght/latest')\n",
    "output.repartition(1).write.csv('/data/search_run/predict_input_lenght/latest', header=True)\n",
    "print(\"Finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}